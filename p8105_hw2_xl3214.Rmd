---
title: "p8105_hw2_xl3214"
output: github_document
author: "Xuan Lu"
date: "`r Sys.Date()`"
---
## Question 0

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
```

```{r github_repository, echo=FALSE}
usethis::use_git_config(
    user.name = "Xuan Lu", 
    user.email = "xuan.lu.080229@gmail.com"
  )
```

```{r library_packages, message = FALSE}
library(tidyverse)
library(dplyr)
```

## Question 1
**STEP 1: Clean dataset pols-month.csv**

Directions: Use `separate()` to break up the variable mon into integer variables *year*, *month*, and *day*; replace month number with month name; create a *president* variable taking values *gop* and *dem*, and remove *prez_dem* and *prez_gop*; and remove the *day* variable.

```{r clean pols_month}
pols_month <- 
  read_csv("./fivethirtyeight_datasets/pols-month.csv") %>% 
  separate(mon, 
         into = c("year","month_num","day"), 
         convert = TRUE) %>% 
  mutate("month" = month.name[month_num]) %>%
  mutate(president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) %>%
  select(year, month, everything(), -day, -prez_gop, -prez_dem, -month_num) 
pols_month
```

**STEP 2: Clean dataset snp.csv**

Directions: Use a similar process to the above. For consistency across datasets, arrange according to *year* and *month*, and organize so that *year* and *month* are the leading columns.

```{r clean snp}
snp <- 
  read_csv("./fivethirtyeight_datasets/snp.csv") %>%
  separate(date, into = c("month", "day", "year"), sep = "/", convert = TRUE) %>%
  arrange(year, month) %>%
  mutate("month" = month.name[month]) %>%
  select(year, month, close) 
snp
```

**STEP 3: Tidy dataset unemployment.csv**

Directions: Tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from `“wide”` to `“long”` format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

```{r clean unemployment}
unemployment <- 
  read_csv("./fivethirtyeight_datasets/unemployment.csv") %>%
  pivot_longer(Jan:Dec, names_to = "month_abb", values_to = "unemployment") %>%
  mutate("month" = factor(month_abb, levels = month.abb, labels = month.name)) %>%
  rename(year = Year) %>%
  select(year, month, unemployment)
unemployment
```

**STEP 4: Merge datasets**

Directions: Join the datasets by merging *snp* into *pols*, and merging *unemployment* into the result.

```{r merging}
data_q1 <- full_join(pols_month, snp, by = c("year","month")) %>%
  full_join(., unemployment, by = c("year","month"))
summary(data_q1)
```

**pols_month**
There are `r nrow(pols_month)` observations and `r ncol(pols_month)` variables in the cleaned *pols_month* dataset, ranges between years of `r min(pols_month$year)` and `r max(pols_month$year)`. Variables are: *`r colnames(pols_month)`*.

**snp**
There are `r nrow(snp)` observations and `r ncol(snp)` variables in the cleaned *snp* dataset, ranges between years of `r min(snp$year)` and `r max(snp$year)`. Variables are: *`r colnames(snp)`*.

**unemployment**
There are `r nrow(unemployment)` observations and `r ncol(unemployment)` variables in the cleaned *unemployment* dataset, ranges between years of `r min(unemployment$year)` and `r max(unemployment$year)`. Variables are: *`r colnames(unemployment)`*.

**merged dataset `data_q1`**
There are a total of `r nrow(data_q1)` observations and `r ncol(data_q1)` variables in the final merged dataset, ranges between years of `r min(data_q1$year)` and `r max(data_q1$year)`. Variables are: *`r colnames(data_q1)`*. Note that I used the `full_join` function with the combination of *year* and *month* as unique identifiers here. This way, all data entries from all tables will be included into the final merged dataset.

## Question 2
**STEP 1: read & clean Mr. Trash Wheel sheet**

Directions: 
* specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in `read_excel`
* use reasonable variable names
* omit rows that do not include dumpster-specific data
* The data include a column for the (approximate) number of homes powered. This calculation is described in the Homes powered note, but not applied to every row in the dataset. Update the data to include a new homes_powered variable based on this calculation.

```{r read and clean the Mr. Trash Wheel sheet}
mr_trash_wheel <- 
  readxl::read_excel("202309\ Trash\ Wheel\ Collection\ Data.xlsx", 
                     sheet = "Mr. Trash Wheel", col_names = TRUE, range = "A2:N586") %>%
  janitor::clean_names() %>%
  mutate("day" = format(date, format="%d")) %>%
  mutate("year" = format(year, format="%Y")) %>%
  select(dumpster, year, month, day, everything(), -date) %>%
  mutate("homes_powered" = (weight_tons*500)/30) %>%
  mutate("dumpster" = paste("mr", dumpster, sep="_"))
mr_trash_wheel
```

I changed the *date* variable in this sheet to *day* as there are *year* and *month* variables. I also changed the format of *year* to character. The Mr. Trash Wheel sheet contains `r ncol(mr_trash_wheel)` variables and `r nrow(mr_trash_wheel)` observations. Variables in this sheet include: *`r colnames(mr_trash_wheel)`*. Variable *dumpster* is the **primary key** that contains values unique to each observation. 

**STEP 2: read & clean Professor Trash Wheel sheet**

```{r}
professor_trash_wheel <- 
  readxl::read_excel("202309\ Trash\ Wheel\ Collection\ Data.xlsx", 
                     sheet = "Professor Trash Wheel", col_names = TRUE, range = "A2:M108") %>%
  janitor::clean_names() %>%
  mutate("day" = format(date, format="%d")) %>%
  mutate("year" = format(year, format="%Y")) %>%
  select(dumpster, year, month, day, everything(), -date) %>%
  mutate("homes_powered" = (weight_tons*500)/30) %>%
  mutate("dumpster" = paste("professor", dumpster, sep="_"))
professor_trash_wheel
```

I changed the *date* variable in this sheet to *day* as there are *year* and *month* variables. I also changed the format of *year* to character. The Professor Trash Wheel sheet contains `r ncol(professor_trash_wheel)` variables and `r nrow(professor_trash_wheel)` observations. Variables in this sheet include: *`r colnames(professor_trash_wheel)`*. Variable *dumpster* is the **primary key** that contains values unique to each observation. 

**STEP 3: read & clean Gwynnda Trash Wheel sheet**

```{r}
gwynnda_trash_wheel <- 
  readxl::read_excel("202309\ Trash\ Wheel\ Collection\ Data.xlsx", 
                     sheet = "Gwynnda Trash Wheel", col_names = TRUE, range = "A2:L157") %>%
  janitor::clean_names() %>%
  mutate("day" = format(date, format="%d")) %>%
  mutate("year" = format(year, format="%Y")) %>%
  select(dumpster, year, month, day, everything(), -date) %>%
  mutate("homes_powered" = (weight_tons*500)/30) %>%
  mutate("dumpster" = paste("gwynnda",  dumpster, sep="_"))
gwynnda_trash_wheel
```

I changed the *date* variable in this sheet to *day* as there are *year* and *month* variables. I also changed the format of *year* to character. The Professor Trash Wheel sheet contains `r ncol(gwynnda_trash_wheel)` variables and `r nrow(gwynnda_trash_wheel)` observations. Variables in this sheet include: *`r colnames(gwynnda_trash_wheel)`*. Variable *dumpster* is the **primary key** that contains values unique to each observation. 

**STEP 4: merge the three sheets**
```{r merge the three sheets}
data_q2 <-
  full_join(mr_trash_wheel, professor_trash_wheel) %>%
  full_join(., gwynnda_trash_wheel)
summary(data_q2)
```

Note that I used the `full_join` function here. This way, all data entries from all tables will be included into the final merged dataset. The merged data contains `r ncol(data_q2)` variables and `r nrow(data_q2)` observations. Variables in this sheet include: *`r colnames(data_q2)`*. Variable *dumpster* is the **primary key** that contains values unique to each observation.

The total weight of trash collected by **Professor Trash Wheel** is `r weight_sum <- data_q2 |> filter(grepl("professor", dumpster)) 
sum(pull(weight_sum, weight_tons))`. The total number of cigarette butts collected by **Gwynnda in July of 2021** is `r cig_sum <- data_q2 %>% filter(grepl("gwynnda", dumpster)) %>% filter(month == "July") %>% filter(year == "2021") 
sum(pull(cig_sum, cigarette_butts))`.

## Question 3
**STEP 1: Clean Baseline Dataset**
Directions: Import, clean, and tidy the dataset of baseline demographics. Ensure that sex and APOE4 carrier status are appropriate encoded (i.e. not numeric), and remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline). 

```{r import and clean the dataset of baseline demographics}
mci_baseline_description <- read_csv("./data_mci/MCI_baseline.csv") %>% colnames()
mci_baseline_description #checking variable descriptions

mci_baseline <- read_csv("./data_mci/MCI_baseline.csv", skip = 1) %>% #use second row as header
  janitor::clean_names() %>% #clean variable names to snake_case
  mutate(sex = recode(sex, "1" = "Male", "0" = "Female")) %>% #recode sex & apoe4 as character variables
  mutate(apoe4 = recode(apoe4, "1" = "APOE4 carrier", "0" = "APOE4 non-carrier")) %>%
  filter(age_at_onset > current_age | age_at_onset == ".") %>%
  mutate(age_at_onset = as.numeric(age_at_onset))
summary(mci_baseline)
```

When importing the dataset, we can notice that the default header of the uncleaned dataset are *`r colnames(mci_baseline_description)`*, which are actually descriptions of each variable. Printing the dataset out, we would notice that the actual header is actually the second row: *`r colnames(mci_baseline)`*. A total of `r nrow(mci_baseline)` participants were recruited, and of these participants, `r nrow(which(pull(mci_baseline, age_at_onset) != "."))` participants developed MCI. The average baseline age is `r mean(pull(mci_baseline, current_age))`, with a range of `r range(pull(mci_baseline, current_age))[1]` to `r range(pull(mci_baseline, current_age))[2]`. `r (count(filter(mci_baseline, apoe4 == "APOE4 carrier" & sex == "Female"))/count(filter(mci_baseline, sex == "Female")))*100`% of women are APOE4 carriers.

**STEP 2: Clean Amyloid Dataset**

Directions: Import, clean, and tidy the dataset of longitudinally observed biomarker values; comment on the steps on the import process and the features of the dataset.

```{r import and clean the dataset of longitudinally observed biomarker values}
mci_amyloid_description <- read_csv("./data_mci/mci_amyloid.csv") %>% colnames()
mci_amyloid_description #checking variable descriptions

mci_amyloid <- read_csv("./data_mci/mci_amyloid.csv", skip = 1) %>% #use second row as header
  janitor::clean_names() %>%  #clean variable names to snake_case
  rename(id = study_id, time_0 = baseline) %>% #rename variables to match baseline dataset
  mutate(time_0 = as.numeric(time_0), time_2 = as.numeric(time_2), time_4 = as.numeric(time_4), time_6 = as.numeric(time_6), time_8 = as.numeric(time_8)) %>% #change character variables of amyroid ratios to numeric
  pivot_longer(., time_0:time_8, names_to = "years_elapsed_since_baseline", values_to = "amyroid_ratio", names_prefix = "time_")  #tidy dataset
summary(mci_amyloid)
```

When importing the dataset, we can notice that the default header of the uncleaned dataset are *`r colnames(mci_amyloid_description)`*, which are actually descriptions of each variable. Printing the dataset out, we would notice that the actual header is actually the second row: *`r colnames(mci_amyloid)`*. 

Check whether some participants appear in only the baseline or amyloid datasets, and comment on your findings. Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset; export the result as a CSV to your data directory.