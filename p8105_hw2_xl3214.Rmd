---
title: "p8105_hw2_xl3214"
output: github_document
author: "Xuan Lu"
date: "`r Sys.Date()`"
---
## Question 0

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
```

```{r github_repository, echo=FALSE}
usethis::use_git_config(
    user.name = "Xuan Lu", 
    user.email = "xuan.lu.080229@gmail.com"
  )
```

```{r library_packages, message = FALSE}
library(tidyverse)
library(dplyr)
```

## Question 1
**STEP 1: Clean dataset pols-month.csv**

Directions: Use `separate()` to break up the variable mon into integer variables *year*, *month*, and *day*; replace month number with month name; create a *president* variable taking values *gop* and *dem*, and remove *prez_dem* and *prez_gop*; and remove the *day* variable.

```{r clean pols_month, message = FALSE}
pols_month <- 
  read_csv("./fivethirtyeight_datasets/pols-month.csv") %>% 
  separate(mon, 
         into = c("year","month_num","day"), 
         convert = TRUE) %>% 
  mutate("month" = month.name[month_num]) %>%
  mutate(president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) %>%
  select(year, month, everything(), -day, -prez_gop, -prez_dem, -month_num) 
pols_month
```

**STEP 2: Clean dataset snp.csv**

Directions: Use a similar process to the above. For consistency across datasets, arrange according to *year* and *month*, and organize so that *year* and *month* are the leading columns.

```{r clean snp, message = FALSE }
snp <- 
  read_csv("./fivethirtyeight_datasets/snp.csv") %>%
  separate(date, into = c("month", "day", "year"), sep = "/", convert = TRUE) %>%
  arrange(year, month) %>%
  mutate("month" = month.name[month]) %>%
  select(year, month, close) 
snp
```

**STEP 3: Tidy dataset unemployment.csv**

Directions: Tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from `“wide”` to `“long”` format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

```{r clean unemployment, message = FALSE}
unemployment <- 
  read_csv("./fivethirtyeight_datasets/unemployment.csv") %>%
  pivot_longer(Jan:Dec, names_to = "month_abb", values_to = "unemployment") %>%
  mutate("month" = factor(month_abb, levels = month.abb, labels = month.name)) %>%
  rename(year = Year) %>%
  select(year, month, unemployment)
unemployment
```

**STEP 4: Merge datasets**

Directions: Join the datasets by merging *snp* into *pols*, and merging *unemployment* into the result.

```{r merging, message = FALSE }
data_q1 <- full_join(pols_month, snp, by = c("year","month")) %>%
  full_join(., unemployment, by = c("year","month"))
summary(data_q1)
```

**pols_month**
There are `r nrow(pols_month)` observations and `r ncol(pols_month)` variables in the cleaned *pols_month* dataset, ranges between years of `r min(pols_month$year)` and `r max(pols_month$year)`. Variables are: *`r colnames(pols_month)`*.

**snp**
There are `r nrow(snp)` observations and `r ncol(snp)` variables in the cleaned *snp* dataset, ranges between years of `r min(snp$year)` and `r max(snp$year)`. Variables are: *`r colnames(snp)`*.

**unemployment**
There are `r nrow(unemployment)` observations and `r ncol(unemployment)` variables in the cleaned *unemployment* dataset, ranges between years of `r min(unemployment$year)` and `r max(unemployment$year)`. Variables are: *`r colnames(unemployment)`*.

**merged dataset `data_q1`**
There are a total of `r nrow(data_q1)` observations and `r ncol(data_q1)` variables in the final merged dataset, ranges between years of `r min(data_q1$year)` and `r max(data_q1$year)`. Variables are: *`r colnames(data_q1)`*. Note that I used the `full_join` function with the combination of *year* and *month* as unique identifiers here. This way, all data entries from all tables will be included into the final merged dataset.

## Question 2
**STEP 1: read & clean Mr. Trash Wheel sheet**

Directions: 

* specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in `read_excel`

* use reasonable variable names

* omit rows that do not include dumpster-specific data

* The data include a column for the (approximate) number of homes powered. This calculation is described in the Homes powered note, but not applied to every row in the dataset. Update the data to include a new homes_powered variable based on this calculation.

```{r read and clean the Mr. Trash Wheel sheet, message = FALSE}
mr_trash_wheel <- 
  readxl::read_excel("202309\ Trash\ Wheel\ Collection\ Data.xlsx", 
                     sheet = "Mr. Trash Wheel", col_names = TRUE, range = "A2:N586") %>%
  janitor::clean_names() %>%
  mutate("day" = format(date, format="%d")) %>%
  mutate("year" = format(year, format="%Y")) %>%
  select(dumpster, year, month, day, everything(), -date) %>%
  mutate("homes_powered" = (weight_tons*500)/30) %>%
  mutate("dumpster" = paste("mr", dumpster, sep="_"))
mr_trash_wheel
```

I changed the *date* variable in this sheet to *day* as there are *year* and *month* variables. I also changed the format of *year* to character. The Mr. Trash Wheel sheet contains `r ncol(mr_trash_wheel)` variables and `r nrow(mr_trash_wheel)` observations. Variables in this sheet include: *`r colnames(mr_trash_wheel)`*. Variable *dumpster* is the **primary key** that contains values unique to each observation. 

**STEP 2: read & clean Professor Trash Wheel sheet**

```{r read and clean the Professor Trash Wheel sheet, message = FALSE}
professor_trash_wheel <- 
  readxl::read_excel("202309\ Trash\ Wheel\ Collection\ Data.xlsx", 
                     sheet = "Professor Trash Wheel", col_names = TRUE, range = "A2:M108") %>%
  janitor::clean_names() %>%
  mutate("day" = format(date, format="%d")) %>%
  mutate("year" = format(year, format="%Y")) %>%
  select(dumpster, year, month, day, everything(), -date) %>%
  mutate("homes_powered" = (weight_tons*500)/30) %>%
  mutate("dumpster" = paste("professor", dumpster, sep="_"))
professor_trash_wheel
```

I changed the *date* variable in this sheet to *day* as there are *year* and *month* variables. I also changed the format of *year* to character. The Professor Trash Wheel sheet contains `r ncol(professor_trash_wheel)` variables and `r nrow(professor_trash_wheel)` observations. Variables in this sheet include: *`r colnames(professor_trash_wheel)`*. Variable *dumpster* is the **primary key** that contains values unique to each observation. 

**STEP 3: read & clean Gwynnda Trash Wheel sheet**

```{r read and clean the Gwynnda Trash Wheel sheet, message = FALSE}
gwynnda_trash_wheel <- 
  readxl::read_excel("202309\ Trash\ Wheel\ Collection\ Data.xlsx", 
                     sheet = "Gwynnda Trash Wheel", col_names = TRUE, range = "A2:L157") %>%
  janitor::clean_names() %>%
  mutate("day" = format(date, format="%d")) %>%
  mutate("year" = format(year, format="%Y")) %>%
  select(dumpster, year, month, day, everything(), -date) %>%
  mutate("homes_powered" = (weight_tons*500)/30) %>%
  mutate("dumpster" = paste("gwynnda",  dumpster, sep="_"))
gwynnda_trash_wheel
```

I changed the *date* variable in this sheet to *day* as there are *year* and *month* variables. I also changed the format of *year* to character. The Professor Trash Wheel sheet contains `r ncol(gwynnda_trash_wheel)` variables and `r nrow(gwynnda_trash_wheel)` observations. Variables in this sheet include: *`r colnames(gwynnda_trash_wheel)`*. Variable *dumpster* is the **primary key** that contains values unique to each observation. 

**STEP 4: merge the three sheets**
```{r merge the three sheets, message = FALSE}
data_q2 <-
  full_join(mr_trash_wheel, professor_trash_wheel) %>%
  full_join(., gwynnda_trash_wheel)
summary(data_q2)
```

Note that I used the `full_join` function here. This way, all data entries from all tables will be included into the final merged dataset. The merged data contains `r ncol(data_q2)` variables and `r nrow(data_q2)` observations. Variables in this sheet include: *`r colnames(data_q2)`*. Variable *dumpster* is the **primary key** that contains values unique to each observation.

The total weight of trash collected by **Professor Trash Wheel** is `r weight_sum <- data_q2 |> filter(grepl("professor", dumpster)) 
sum(pull(weight_sum, weight_tons))`. The total number of cigarette butts collected by **Gwynnda in July of 2021** is `r cig_sum <- data_q2 %>% filter(grepl("gwynnda", dumpster)) %>% filter(month == "July") %>% filter(year == "2021") 
sum(pull(cig_sum, cigarette_butts))`.

## Question 3
**STEP 1: Clean Baseline Dataset**

Directions: Import, clean, and tidy the dataset of baseline demographics. Ensure that sex and APOE4 carrier status are appropriate encoded (i.e. not numeric), and remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline). 

```{r import and clean the dataset of baseline demographics, message = FALSE, warning = FALSE}
mci_baseline_description <- read_csv("./data_mci/MCI_baseline.csv") %>% colnames()
mci_baseline_description #checking variable descriptions

mci_baseline <- read_csv("./data_mci/MCI_baseline.csv", skip = 1) %>% #use second row as header
  janitor::clean_names() %>% #clean variable names to snake_case
  mutate(sex = recode(sex, "1" = "Male", "0" = "Female")) %>% #recode sex & apoe4 as character variables
  mutate(apoe4 = recode(apoe4, "1" = "APOE4 carrier", "0" = "APOE4 non-carrier")) %>%
  filter(age_at_onset > current_age | age_at_onset == ".") %>%
  mutate(age_at_onset = as.numeric(age_at_onset))
summary(mci_baseline)
```

When importing the dataset, we can notice that the default header of the uncleaned dataset are actually descriptions of each variable. Printing the dataset out, we would notice that the actual header is actually the second row: *`r colnames(mci_baseline)`*. 

A total of `r nrow(mci_baseline)` participants were recruited, and of these participants, `r mci_baseline %>% 
filter(!is.na(age_at_onset)) %>% 
nrow()` participants developed MCI. The average baseline age is `r mean(pull(mci_baseline, current_age))`, with a range of `r range(pull(mci_baseline, current_age))[1]` to `r range(pull(mci_baseline, current_age))[2]`. `r (count(filter(mci_baseline, apoe4 == "APOE4 carrier" & sex == "Female"))/count(filter(mci_baseline, sex == "Female")))*100`% of women are APOE4 carriers.

**STEP 2: Clean Amyloid Dataset**

Directions: Import, clean, and tidy the dataset of longitudinally observed biomarker values; comment on the steps on the import process and the features of the dataset.

```{r import and clean the dataset of longitudinally observed biomarker values, message = FALSE, warning = FALSE}
mci_amyloid_description <- read_csv("./data_mci/mci_amyloid.csv") %>% colnames()
mci_amyloid_description #checking variable descriptions

mci_amyloid <- read_csv("./data_mci/mci_amyloid.csv", skip = 1) %>% #use second row as header
  janitor::clean_names() %>%  #clean variable names to snake_case
  rename(id = study_id, time_0 = baseline) %>% #rename variables to match baseline dataset
  mutate(time_0 = as.numeric(time_0), time_2 = as.numeric(time_2), time_4 = as.numeric(time_4),
         time_6 = as.numeric(time_6), time_8 = as.numeric(time_8)) %>% #change character variables of amyroid ratios to numeric
  pivot_longer(., time_0:time_8, names_to = "years_elapsed_since_baseline", values_to = "amyroid_ratio", names_prefix = "time_")  #tidy dataset
summary(mci_amyloid)
```

There are a total of `r nrow(mci_amyloid)` observations, `r length(unique(mci_amyloid$id))` unique participants and `r ncol(mci_amyloid)` variables in this dataset. When importing the dataset, we can notice that the default header of the uncleaned dataset are actually descriptions of each variable. Printing the dataset out, we would notice that the actual header is actually the second row: *`r colnames(mci_amyloid)`*. To tidy the dataset, I used `pivot_longer` function to change several columns of different times of followup to rows. 

There are `r length(unique(subset(mci_baseline, !id %in% mci_amyloid$id)$id))` participants who appeared in only the baseline dataset but not the amyloid dataset, and `r length(unique(subset(mci_amyloid, !id %in% mci_baseline$id)$id))` participants who appeared in only the amyloid dataset not the baseline dataset. To ensure that only participants with entries in both dataset are included into the final dataset, I will merge the two datasets using the `inner_join` function. 

```{r merge the baseline & amyloid datasets,  message = FALSE}
data_q3 <- inner_join(mci_baseline, mci_amyloid, by = "id")
summary(data_q3)
```

There are `r nrow(data_q3)` observations, `r length(unique(data_q3$id))` unique participants, and `r ncol(data_q3)` variables in the final merged dataset for MCI. Variables include *`r colnames(data_q3)`*. 
An Aβ42/40 ratio <0.150 suggests a higher risk of having of AD pathology compared to higher values. 
2 years after baseline, `r length(unique(filter(data_q3, amyroid_ratio < 0.15 & years_elapsed_since_baseline == 2))$id)/length(unique(filter(data_q3, years_elapsed_since_baseline == 2))$id)*100`% of participants have An Aβ42/40 ratio <0.150. 
4 years after baseline, the proportion increased to `r length(unique(filter(data_q3, amyroid_ratio < 0.15 & years_elapsed_since_baseline == 4))$id)/length(unique(filter(data_q3, years_elapsed_since_baseline == 4))$id)*100`%. 
6 years after baseline, the proportion increased to `r length(unique(filter(data_q3, amyroid_ratio < 0.15 & years_elapsed_since_baseline == 6))$id)/length(unique(filter(data_q3, years_elapsed_since_baseline == 6))$id)*100`%. 
8 years after baseline, the proportion increased to `r length(unique(filter(data_q3, amyroid_ratio < 0.15 & years_elapsed_since_baseline == 8))$id)/length(unique(filter(data_q3, years_elapsed_since_baseline == 8))$id)*100`%. 
Among those that are female, the proportion of having an Aβ42/40 ratio <0.150 8 years after baseline is `r length(unique(filter(data_q3, amyroid_ratio < 0.15 & years_elapsed_since_baseline == 8 & sex == "Female"))$id)/length(unique(filter(data_q3, years_elapsed_since_baseline == 8 & sex == "Female"))$id)*100`%. 
This proportion is `r length(unique(filter(data_q3, amyroid_ratio < 0.15 & years_elapsed_since_baseline == 8 & sex == "Male"))$id)/length(unique(filter(data_q3, years_elapsed_since_baseline == 8 & sex == "Male"))$id)*100`% for males. 

```{r export final result data_q3 into a CSV file to my data directory,  message = FALSE}
write.csv(data_q3, file = "data_q3.csv")
```