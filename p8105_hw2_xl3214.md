p8105_hw2_xl3214
================
Xuan Lu
2023-10-04

## Question 0

``` r
library(tidyverse)
library(dplyr)
```

## Question 1

**STEP 1: Clean dataset pols-month.csv**

Directions: Use `separate()` to break up the variable mon into integer
variables *year*, *month*, and *day*; replace month number with month
name; create a *president* variable taking values *gop* and *dem*, and
remove *prez_dem* and *prez_gop*; and remove the *day* variable.

``` r
pols_month <- 
  read_csv("./fivethirtyeight_datasets/pols-month.csv") %>% 
  separate(mon, 
         into = c("year","month_num","day"), 
         convert = TRUE) %>% 
  mutate("month" = month.name[month_num]) %>%
  mutate(president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) %>%
  select(year, month, everything(), -day, -prez_gop, -prez_dem, -month_num) 
pols_month
## # A tibble: 822 × 9
##     year month     gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
##    <int> <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
##  1  1947 January        23      51     253      23      45     198 dem      
##  2  1947 February       23      51     253      23      45     198 dem      
##  3  1947 March          23      51     253      23      45     198 dem      
##  4  1947 April          23      51     253      23      45     198 dem      
##  5  1947 May            23      51     253      23      45     198 dem      
##  6  1947 June           23      51     253      23      45     198 dem      
##  7  1947 July           23      51     253      23      45     198 dem      
##  8  1947 August         23      51     253      23      45     198 dem      
##  9  1947 September      23      51     253      23      45     198 dem      
## 10  1947 October        23      51     253      23      45     198 dem      
## # ℹ 812 more rows
```

**STEP 2: Clean dataset snp.csv**

Directions: Use a similar process to the above. For consistency across
datasets, arrange according to *year* and *month*, and organize so that
*year* and *month* are the leading columns.

``` r
snp <- 
  read_csv("./fivethirtyeight_datasets/snp.csv") %>%
  separate(date, into = c("month", "day", "year"), sep = "/", convert = TRUE) %>%
  arrange(year, month) %>%
  mutate("month" = month.name[month]) %>%
  select(year, month, close) 
snp
## # A tibble: 787 × 3
##     year month     close
##    <int> <chr>     <dbl>
##  1     0 January   1394.
##  2     0 February  1366.
##  3     0 March     1499.
##  4     0 April     1452.
##  5     0 May       1421.
##  6     0 June      1455.
##  7     0 July      1431.
##  8     0 August    1518.
##  9     0 September 1437.
## 10     0 October   1429.
## # ℹ 777 more rows
```

**STEP 3: Tidy dataset unemployment.csv**

Directions: Tidy the unemployment data so that it can be merged with the
previous datasets. This process will involve switching from `“wide”` to
`“long”` format; ensuring that key variables have the same name; and
ensuring that key variables take the same values.

``` r
unemployment <- 
  read_csv("./fivethirtyeight_datasets/unemployment.csv") %>%
  pivot_longer(Jan:Dec, names_to = "month_abb", values_to = "unemployment") %>%
  mutate("month" = factor(month_abb, levels = month.abb, labels = month.name)) %>%
  rename(year = Year) %>%
  select(year, month, unemployment)
unemployment
## # A tibble: 816 × 3
##     year month     unemployment
##    <dbl> <fct>            <dbl>
##  1  1948 January            3.4
##  2  1948 February           3.8
##  3  1948 March              4  
##  4  1948 April              3.9
##  5  1948 May                3.5
##  6  1948 June               3.6
##  7  1948 July               3.6
##  8  1948 August             3.9
##  9  1948 September          3.8
## 10  1948 October            3.7
## # ℹ 806 more rows
```

**STEP 4: Merge datasets**

Directions: Join the datasets by merging *snp* into *pols*, and merging
*unemployment* into the result.

``` r
data_q1 <- full_join(pols_month, snp, by = c("year","month")) %>%
  full_join(., unemployment, by = c("year","month"))
summary(data_q1)
##       year         month              gov_gop         sen_gop    
##  Min.   :   0   Length:1615        Min.   :12.00   Min.   :32.0  
##  1st Qu.:  68   Class :character   1st Qu.:18.00   1st Qu.:42.0  
##  Median :1948   Mode  :character   Median :22.00   Median :46.0  
##  Mean   :1044                      Mean   :22.48   Mean   :46.1  
##  3rd Qu.:1982                      3rd Qu.:28.00   3rd Qu.:51.0  
##  Max.   :2015                      Max.   :34.00   Max.   :56.0  
##                                    NA's   :793     NA's   :793   
##     rep_gop         gov_dem        sen_dem         rep_dem   
##  Min.   :141.0   Min.   :17.0   Min.   :44.00   Min.   :188  
##  1st Qu.:176.0   1st Qu.:22.0   1st Qu.:48.00   1st Qu.:211  
##  Median :195.0   Median :28.0   Median :53.00   Median :250  
##  Mean   :194.9   Mean   :27.2   Mean   :54.41   Mean   :245  
##  3rd Qu.:222.0   3rd Qu.:32.0   3rd Qu.:58.00   3rd Qu.:268  
##  Max.   :253.0   Max.   :41.0   Max.   :71.00   Max.   :301  
##  NA's   :793     NA's   :793    NA's   :793     NA's   :793  
##   president             close          unemployment  
##  Length:1615        Min.   :  17.05   Min.   : 2.50  
##  Class :character   1st Qu.:  83.73   1st Qu.: 4.70  
##  Mode  :character   Median : 138.53   Median : 5.60  
##                     Mean   : 474.89   Mean   : 5.83  
##                     3rd Qu.: 941.79   3rd Qu.: 6.90  
##                     Max.   :2107.39   Max.   :10.80  
##                     NA's   :828       NA's   :805
```

**pols_month** There are 822 observations and 9 variables in the cleaned
*pols_month* dataset, ranges between years of 1947 and 2015. Variables
are: *year, month, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem,
president*.

**snp** There are 787 observations and 3 variables in the cleaned *snp*
dataset, ranges between years of 0 and 99. Variables are: *year, month,
close*.

**unemployment** There are 816 observations and 3 variables in the
cleaned *unemployment* dataset, ranges between years of 1948 and 2015.
Variables are: *year, month, unemployment*.

**merged dataset `data_q1`** There are a total of 1615 observations and
11 variables in the final merged dataset, ranges between years of 0 and
2015. Variables are: *year, month, gov_gop, sen_gop, rep_gop, gov_dem,
sen_dem, rep_dem, president, close, unemployment*. Note that I used the
`full_join` function with the combination of *year* and *month* as
unique identifiers here. This way, all data entries from all tables will
be included into the final merged dataset.

## Question 2

**STEP 1: read & clean Mr. Trash Wheel sheet**

Directions:

- specify the sheet in the Excel file and to omit non-data entries (rows
  with notes / figures; columns containing notes) using arguments in
  `read_excel`

- use reasonable variable names

- omit rows that do not include dumpster-specific data

- The data include a column for the (approximate) number of homes
  powered. This calculation is described in the Homes powered note, but
  not applied to every row in the dataset. Update the data to include a
  new homes_powered variable based on this calculation.

``` r
mr_trash_wheel <- 
  readxl::read_excel("202309\ Trash\ Wheel\ Collection\ Data.xlsx", 
                     sheet = "Mr. Trash Wheel", col_names = TRUE, range = "A2:N586") %>%
  janitor::clean_names() %>%
  mutate("day" = format(date, format="%d")) %>%
  mutate("year" = format(year, format="%Y")) %>%
  select(dumpster, year, month, day, everything(), -date) %>%
  mutate("homes_powered" = (weight_tons*500)/30) %>%
  mutate("dumpster" = paste("mr", dumpster, sep="_"))
mr_trash_wheel
## # A tibble: 584 × 14
##    dumpster year  month day   weight_tons volume_cubic_yards plastic_bottles
##    <chr>    <chr> <chr> <chr>       <dbl>              <dbl>           <dbl>
##  1 mr_1     2014  May   16           4.31                 18            1450
##  2 mr_2     2014  May   16           2.74                 13            1120
##  3 mr_3     2014  May   16           3.45                 15            2450
##  4 mr_4     2014  May   17           3.1                  15            2380
##  5 mr_5     2014  May   17           4.06                 18             980
##  6 mr_6     2014  May   20           2.71                 13            1430
##  7 mr_7     2014  May   21           1.91                  8             910
##  8 mr_8     2014  May   28           3.7                  16            3580
##  9 mr_9     2014  June  05           2.52                 14            2400
## 10 mr_10    2014  June  11           3.76                 18            1340
## # ℹ 574 more rows
## # ℹ 7 more variables: polystyrene <dbl>, cigarette_butts <dbl>,
## #   glass_bottles <dbl>, plastic_bags <dbl>, wrappers <dbl>,
## #   sports_balls <dbl>, homes_powered <dbl>
```

I changed the *date* variable in this sheet to *day* as there are *year*
and *month* variables. I also changed the format of *year* to character.
The Mr. Trash Wheel sheet contains 14 variables and 584 observations.
Variables in this sheet include: *dumpster, year, month, day,
weight_tons, volume_cubic_yards, plastic_bottles, polystyrene,
cigarette_butts, glass_bottles, plastic_bags, wrappers, sports_balls,
homes_powered*. Variable *dumpster* is the **primary key** that contains
values unique to each observation.

**STEP 2: read & clean Professor Trash Wheel sheet**

``` r
professor_trash_wheel <- 
  readxl::read_excel("202309\ Trash\ Wheel\ Collection\ Data.xlsx", 
                     sheet = "Professor Trash Wheel", col_names = TRUE, range = "A2:M108") %>%
  janitor::clean_names() %>%
  mutate("day" = format(date, format="%d")) %>%
  mutate("year" = format(year, format="%Y")) %>%
  select(dumpster, year, month, day, everything(), -date) %>%
  mutate("homes_powered" = (weight_tons*500)/30) %>%
  mutate("dumpster" = paste("professor", dumpster, sep="_"))
professor_trash_wheel
## # A tibble: 106 × 13
##    dumpster     year  month day   weight_tons volume_cubic_yards plastic_bottles
##    <chr>        <chr> <chr> <chr>       <dbl>              <dbl>           <dbl>
##  1 professor_1  2017  Janu… 02           1.79                 15            1950
##  2 professor_2  2017  Janu… 30           1.58                 15            9540
##  3 professor_3  2017  Febr… 26           2.32                 18            8350
##  4 professor_4  2017  Febr… 26           3.72                 15            8590
##  5 professor_5  2017  Febr… 28           1.45                 15            7830
##  6 professor_6  2017  March 30           1.71                 15            8210
##  7 professor_7  2017  April 01           1.82                 15            9830
##  8 professor_8  2017  April 20           2.37                 15            9240
##  9 professor_9  2017  May   10           2.64                 15            9540
## 10 professor_10 2017  May   26           2.78                 15            8230
## # ℹ 96 more rows
## # ℹ 6 more variables: polystyrene <dbl>, cigarette_butts <dbl>,
## #   glass_bottles <dbl>, plastic_bags <dbl>, wrappers <dbl>,
## #   homes_powered <dbl>
```

I changed the *date* variable in this sheet to *day* as there are *year*
and *month* variables. I also changed the format of *year* to character.
The Professor Trash Wheel sheet contains 13 variables and 106
observations. Variables in this sheet include: *dumpster, year, month,
day, weight_tons, volume_cubic_yards, plastic_bottles, polystyrene,
cigarette_butts, glass_bottles, plastic_bags, wrappers, homes_powered*.
Variable *dumpster* is the **primary key** that contains values unique
to each observation.

**STEP 3: read & clean Gwynnda Trash Wheel sheet**

``` r
gwynnda_trash_wheel <- 
  readxl::read_excel("202309\ Trash\ Wheel\ Collection\ Data.xlsx", 
                     sheet = "Gwynnda Trash Wheel", col_names = TRUE, range = "A2:L157") %>%
  janitor::clean_names() %>%
  mutate("day" = format(date, format="%d")) %>%
  mutate("year" = format(year, format="%Y")) %>%
  select(dumpster, year, month, day, everything(), -date) %>%
  mutate("homes_powered" = (weight_tons*500)/30) %>%
  mutate("dumpster" = paste("gwynnda",  dumpster, sep="_"))
gwynnda_trash_wheel
## # A tibble: 155 × 12
##    dumpster   year  month  day   weight_tons volume_cubic_yards plastic_bottles
##    <chr>      <chr> <chr>  <chr>       <dbl>              <dbl>           <dbl>
##  1 gwynnda_1  2021  July   03           0.93                 15            1200
##  2 gwynnda_2  2021  July   07           2.26                 15            2000
##  3 gwynnda_3  2021  July   07           1.62                 15            1800
##  4 gwynnda_4  2021  July   16           1.76                 15            1000
##  5 gwynnda_5  2021  July   30           1.53                 15            2100
##  6 gwynnda_6  2021  August 11           2.06                 15            2400
##  7 gwynnda_7  2021  August 14           1.9                  15            2700
##  8 gwynnda_8  2021  August 16           2.16                 15            3000
##  9 gwynnda_9  2021  August 16           2.6                  15             980
## 10 gwynnda_10 2021  August 17           3.21                 15             240
## # ℹ 145 more rows
## # ℹ 5 more variables: polystyrene <dbl>, cigarette_butts <dbl>,
## #   plastic_bags <dbl>, wrappers <dbl>, homes_powered <dbl>
```

I changed the *date* variable in this sheet to *day* as there are *year*
and *month* variables. I also changed the format of *year* to character.
The Professor Trash Wheel sheet contains 12 variables and 155
observations. Variables in this sheet include: *dumpster, year, month,
day, weight_tons, volume_cubic_yards, plastic_bottles, polystyrene,
cigarette_butts, plastic_bags, wrappers, homes_powered*. Variable
*dumpster* is the **primary key** that contains values unique to each
observation.

**STEP 4: merge the three sheets**

``` r
data_q2 <-
  full_join(mr_trash_wheel, professor_trash_wheel) %>%
  full_join(., gwynnda_trash_wheel)
summary(data_q2)
##    dumpster             year              month               day           
##  Length:845         Length:845         Length:845         Length:845        
##  Class :character   Class :character   Class :character   Class :character  
##  Mode  :character   Mode  :character   Mode  :character   Mode  :character  
##                                                                             
##                                                                             
##                                                                             
##                                                                             
##   weight_tons    volume_cubic_yards plastic_bottles  polystyrene   
##  Min.   :0.610   Min.   : 5.00      Min.   :   0    Min.   :    0  
##  1st Qu.:2.490   1st Qu.:15.00      1st Qu.:1000    1st Qu.:  280  
##  Median :3.070   Median :15.00      Median :1980    Median :  950  
##  Mean   :3.009   Mean   :15.13      Mean   :2296    Mean   : 1631  
##  3rd Qu.:3.540   3rd Qu.:15.00      3rd Qu.:2900    3rd Qu.: 2400  
##  Max.   :5.620   Max.   :20.00      Max.   :9830    Max.   :11528  
##                                     NA's   :1       NA's   :1      
##  cigarette_butts  glass_bottles     plastic_bags      wrappers    
##  Min.   :     0   Min.   :  0.00   Min.   :    0   Min.   :  180  
##  1st Qu.:  3200   1st Qu.: 10.00   1st Qu.:  280   1st Qu.:  840  
##  Median :  5500   Median : 18.00   Median :  680   Median : 1380  
##  Mean   : 15592   Mean   : 20.89   Mean   : 1082   Mean   : 2330  
##  3rd Qu.: 16000   3rd Qu.: 28.00   3rd Qu.: 1400   3rd Qu.: 2635  
##  Max.   :310000   Max.   :110.00   Max.   :13450   Max.   :20100  
##  NA's   :1        NA's   :156      NA's   :1       NA's   :118    
##   sports_balls   homes_powered  
##  Min.   : 0.00   Min.   :10.17  
##  1st Qu.: 6.00   1st Qu.:41.50  
##  Median :11.00   Median :51.17  
##  Mean   :13.17   Mean   :50.16  
##  3rd Qu.:18.25   3rd Qu.:59.00  
##  Max.   :56.00   Max.   :93.67  
##  NA's   :261
```

Note that I used the `full_join` function here. This way, all data
entries from all tables will be included into the final merged dataset.
The merged data contains 14 variables and 845 observations. Variables in
this sheet include: *dumpster, year, month, day, weight_tons,
volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
glass_bottles, plastic_bags, wrappers, sports_balls, homes_powered*.
Variable *dumpster* is the **primary key** that contains values unique
to each observation.

The total weight of trash collected by **Professor Trash Wheel** is
216.26. The total number of cigarette butts collected by **Gwynnda in
July of 2021** is 1.63^{4}.

## Question 3

**STEP 1: Clean Baseline Dataset**

Directions: Import, clean, and tidy the dataset of baseline
demographics. Ensure that sex and APOE4 carrier status are appropriate
encoded (i.e. not numeric), and remove any participants who do not meet
the stated inclusion criteria (i.e. no MCI at baseline).

``` r
mci_baseline_description <- read_csv("./data_mci/MCI_baseline.csv") %>% colnames()
mci_baseline_description #checking variable descriptions
## [1] "...1"                                                                                      
## [2] "Age at the study baseline"                                                                 
## [3] "1 = Male, 0 = Female"                                                                      
## [4] "Years of education"                                                                        
## [5] "1 = APOE4 carrier, 0 = APOE4 non-carrier"                                                  
## [6] "Age at the onset of MCI; missing if a subject remains MCI free during the follow-up period"

mci_baseline <- read_csv("./data_mci/MCI_baseline.csv", skip = 1) %>% #use second row as header
  janitor::clean_names() %>% #clean variable names to snake_case
  mutate(sex = recode(sex, "1" = "Male", "0" = "Female")) %>% #recode sex & apoe4 as character variables
  mutate(apoe4 = recode(apoe4, "1" = "APOE4 carrier", "0" = "APOE4 non-carrier")) %>%
  filter(age_at_onset > current_age | age_at_onset == ".") %>%
  mutate(age_at_onset = as.numeric(age_at_onset))
summary(mci_baseline)
##        id         current_age        sex              education   
##  Min.   :  1.0   Min.   :56.00   Length:479         Min.   :12.0  
##  1st Qu.:121.5   1st Qu.:63.15   Class :character   1st Qu.:16.0  
##  Median :242.0   Median :64.90   Mode  :character   Median :16.0  
##  Mean   :242.0   Mean   :65.03                      Mean   :16.4  
##  3rd Qu.:362.5   3rd Qu.:67.00                      3rd Qu.:18.0  
##  Max.   :483.0   Max.   :72.90                      Max.   :20.0  
##                                                                   
##     apoe4            age_at_onset  
##  Length:479         Min.   :61.20  
##  Class :character   1st Qu.:68.20  
##  Mode  :character   Median :70.20  
##                     Mean   :70.41  
##                     3rd Qu.:73.40  
##                     Max.   :77.20  
##                     NA's   :386
```

When importing the dataset, we can notice that the default header of the
uncleaned dataset are actually descriptions of each variable. Printing
the dataset out, we would notice that the actual header is actually the
second row: *id, current_age, sex, education, apoe4, age_at_onset*.

A total of 479 participants were recruited, and of these participants,
93 participants developed MCI. The average baseline age is 65.0286013,
with a range of 56 to 72.9. 30% of women are APOE4 carriers.

**STEP 2: Clean Amyloid Dataset**

Directions: Import, clean, and tidy the dataset of longitudinally
observed biomarker values; comment on the steps on the import process
and the features of the dataset.

``` r
mci_amyloid_description <- read_csv("./data_mci/mci_amyloid.csv") %>% colnames()
mci_amyloid_description #checking variable descriptions
## [1] "Study ID"                                                                                                        
## [2] "Time (in years) elapsed since the study baseline to the visit where biomarker Amyloid _ 42/40 ratio was measured"
## [3] "NA...3"                                                                                                          
## [4] "NA...4"                                                                                                          
## [5] "NA...5"                                                                                                          
## [6] "NA...6"

mci_amyloid <- read_csv("./data_mci/mci_amyloid.csv", skip = 1) %>% #use second row as header
  janitor::clean_names() %>%  #clean variable names to snake_case
  rename(id = study_id, time_0 = baseline) %>% #rename variables to match baseline dataset
  mutate(time_0 = as.numeric(time_0), time_2 = as.numeric(time_2), time_4 = as.numeric(time_4),
         time_6 = as.numeric(time_6), time_8 = as.numeric(time_8)) %>% #change character variables of amyroid ratios to numeric
  pivot_longer(., time_0:time_8, names_to = "years_elapsed_since_baseline", values_to = "amyroid_ratio", names_prefix = "time_")  #tidy dataset
summary(mci_amyloid)
##        id        years_elapsed_since_baseline amyroid_ratio    
##  Min.   :  1.0   Length:2435                  Min.   :0.09938  
##  1st Qu.:125.0   Class :character             1st Qu.:0.10752  
##  Median :248.0   Mode  :character             Median :0.10967  
##  Mean   :248.6                                Mean   :0.10969  
##  3rd Qu.:372.0                                3rd Qu.:0.11187  
##  Max.   :495.0                                Max.   :0.11871  
##                                               NA's   :172
```

When importing the dataset, we can notice that the default header of the
uncleaned dataset are actually descriptions of each variable. Printing
the dataset out, we would notice that the actual header is actually the
second row: *id, years_elapsed_since_baseline, amyroid_ratio*. To tidy
the dataset, I used `pivot_longer` function to change several columns of
different times of followup to rows.

There are 8 participants who appeared in only the baseline dataset but
not the amyloid dataset, and 16 participants who appeared in only the
amyloid dataset not the baseline dataset. To ensure that only
participants with entries in both dataset are included into the final
dataset, I will merge the two datasets using the `inner_join` function.

``` r
data_q3 <- inner_join(mci_baseline, mci_amyloid, by = "id")
summary(data_q3)
##        id         current_age        sex              education    
##  Min.   :  1.0   Min.   :56.00   Length:2355        Min.   :12.00  
##  1st Qu.:122.0   1st Qu.:63.20   Class :character   1st Qu.:16.00  
##  Median :242.0   Median :64.90   Mode  :character   Median :16.00  
##  Mean   :242.5   Mean   :65.05                      Mean   :16.38  
##  3rd Qu.:363.0   3rd Qu.:67.00                      3rd Qu.:18.00  
##  Max.   :483.0   Max.   :72.90                      Max.   :20.00  
##                                                                    
##     apoe4            age_at_onset   years_elapsed_since_baseline
##  Length:2355        Min.   :61.20   Length:2355                 
##  Class :character   1st Qu.:68.40   Class :character            
##  Mode  :character   Median :70.35   Mode  :character            
##                     Mean   :70.51                               
##                     3rd Qu.:73.60                               
##                     Max.   :77.20                               
##                     NA's   :1905                                
##  amyroid_ratio    
##  Min.   :0.09938  
##  1st Qu.:0.10752  
##  Median :0.10967  
##  Mean   :0.10969  
##  3rd Qu.:0.11188  
##  Max.   :0.11871  
##  NA's   :167
```

There are 2355 observations, 471 unique participants, and 8 variables in
the final merged dataset for MCI. Variables include *id, current_age,
sex, education, apoe4, age_at_onset, years_elapsed_since_baseline,
amyroid_ratio*. An Aβ42/40 ratio \<0.150 suggests a higher risk of
having of AD pathology compared to higher values. 2 years after
baseline, 89.596603% of participants have An Aβ42/40 ratio \<0.150. 4
years after baseline, the proportion increased to 91.0828025%. 6 years
after baseline, the proportion increased to 91.7197452%. 8 years after
baseline, the proportion increased to 92.3566879%. Among those that are
female, the proportion of having an Aβ42/40 ratio \<0.150 8 years after
baseline is 91.7073171%. This proportion is 92.8571429% for males.

``` r
write.csv(data_q3, file = "data_q3.csv", row.names = FALSE, col.names = TRUE)
## Warning in write.csv(data_q3, file = "data_q3.csv", row.names = FALSE,
## col.names = TRUE): attempt to set 'col.names' ignored
```
